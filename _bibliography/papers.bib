---
---
@article{guo2024ai,
  abbr={Arxiv},
  bibtex_show={true},
  title={AI-generated Image Detection: Passive or Watermark?},
  author={Guo, Moyang and Hu, Yuepeng and Jiang, Zhengyuan and Li, Zeyu and Sadovnik, Amir and Daw, Arka and Gong, Neil},
  abstract={While text-to-image models offer numerous benefits, they also pose significant societal risks. Detecting AI-generated images is crucial for mitigating these risks. Detection methods can be broadly categorized into passive and watermark-based approaches: passive detectors rely on artifacts present in AI-generated images, whereas watermark-based detectors proactively embed watermarks into such images. A key question is which type of detector performs better in terms of effectiveness, robustness, and efficiency. However, the current literature lacks a comprehensive understanding of this issue. In this work, we aim to bridge that gap by developing ImageDetectBench, the first comprehensive benchmark to compare the effectiveness, robustness, and efficiency of passive and watermark-based detectors. Our benchmark includes four datasets, each containing a mix of AI-generated and non-AI-generated images. We evaluate five passive detectors and four watermark-based detectors against eight types of common perturbations and three types of adversarial perturbations. Our benchmark results reveal several interesting findings. For instance, watermark-based detectors consistently outperform passive detectors, both in the presence and absence of perturbations. Based on these insights, we provide recommendations for detecting AI-generated images, e.g., when both types of detectors are applicable, watermark-based detectors should be the preferred choice.},
  journal={arXiv preprint arXiv:2411.13553},
  year={2024},
  publisher={Arxiv},
  html={https://arxiv.org/abs/2411.13553}
}

@article{daw2024hiding,
  abbr={NeurIPS 2024},
  bibtex_show={true},
  title={Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images},
  author={Daw, Arka and Chung, Megan Hong-Thanh and Mahbub, Maria and Sadovnik, Amir},
  abstract={Machine learning models are known to be vulnerable to adversarial attacks, but traditional attacks have mostly focused on single-modalities. With the rise of large multi-modal models (LMMs) like CLIP, which combine vision and language capabilities, new vulnerabilities have emerged. However, prior work in multimodal targeted attacks aim to completely change the model's output to what the adversary wants. In many realistic scenarios, an adversary might seek to make only subtle modifications to the output, so that the changes go unnoticed by downstream models or even by humans. We introduce Hiding-in-Plain-Sight (HiPS) attacks, a novel class of adversarial attacks that subtly modifies model predictions by selectively concealing target object(s), as if the target object was absent from the scene. We propose two HiPS attack variants, HiPS-cls and HiPS-cap, and demonstrate their effectiveness in transferring to downstream image captioning models, such as CLIP-Cap, for targeted object removal from image captions.},
  journal={Adversarial Frontiers Workshop at NeurIPS 2024},
  year={2024},
  publisher={NeurIPS},
  html={https://arxiv.org/abs/2410.13010}
}

@inproceedings{neogmasking,
  abbr={NeurIPS 2024},
  bibtex_show={true},
  title={Masking the Gaps: An Imputation-Free Approach to Time Series Modeling with Missing Data},
  author={Neog, Abhilash and Daw, Arka and Khorasgani, Sepideh Fatemi and Karpatne, Anuj},
  abstract={A significant challenge in time-series (TS) modelling is presence of missing values in real-world TS datasets. Traditional two-stage frameworks, involving imputation followed by modeling, suffer from two key drawbacks: (1) the propagation of imputation errors into subsequent TS modeling, (2) the trade-offs between imputation efficacy and imputation complexity. While one-stage approaches attempt to address these limitations, they often struggle with scalability or fully leveraging partially observed features. To this end, we propose a novel imputation-free approach for handling missing values in time series termed \textbf{Miss}ing Feature-aware \textbf{T}ime \textbf{S}eries \textbf{M}odeling (\textbf{MissTSM}) with two main innovations. \textit{First}, we develop a novel embedding scheme that treats every combination of time-step and feature (or channel) as a distinct token. \textit{Second}, we introduce a novel \textit{Missing Feature-Aware Attention (MFAA) Layer} to learn latent representations at every time-step based on partially observed features. We evaluate the effectiveness of MissTSM in handling missing values over multiple benchmark datasets.},
  booktitle={NeurIPS Workshop on Time Series in the Age of Large Models},
  year={2024},
  publisher={NeurIPS},
}

@article{gupta2024unified,
  abbr={Arxiv},
  bibtex_show={true},
  title={A Unified Framework for Forward and Inverse Problems in Subsurface Imaging using Latent Space Translations},
  author={Gupta, Naveen and Sawhney, Medha and Daw, Arka and Lin, Youzuo and Karpatne, Anuj},
  abstract={In subsurface imaging, learning the mapping from velocity maps to seismic waveforms (forward problem) and waveforms to velocity (inverse problem) is important for several applications. While traditional techniques for solving forward and inverse problems are computationally prohibitive, there is a growing interest in leveraging recent advances in deep learning to learn the mapping between velocity maps and seismic waveform images directly from data. Despite the variety of architectures explored in previous works, several open questions still remain unanswered such as the effect of latent space sizes, the importance of manifold learning, the complexity of translation models, and the value of jointly solving forward and inverse problems. We propose a unified framework to systematically characterize prior research in this area termed the Generalized Forward-Inverse (GFI) framework, building on the assumption of manifolds and latent space translations. We show that GFI encompasses previous works in deep learning for subsurface imaging, which can be viewed as specific instantiations of GFI. We also propose two new model architectures within the framework of GFI: Latent U-Net and Invertible X-Net, leveraging the power of U-Nets for domain translation and the ability of IU-Nets to simultaneously learn forward and inverse translations, respectively. We show that our proposed models achieve state-of-the-art (SOTA) performance for forward and inverse problems on a wide range of synthetic datasets, and also investigate their zero-shot effectiveness on two real-world-like datasets.},
  journal={arXiv preprint arXiv:2410.11247},
  year={2024},
  publisher={Arxiv},
  html={https://arxiv.org/abs/2410.11247}
}

@article{manogaran2024you,
  abbr={Arxiv},
  bibtex_show={true},
  title={What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits},
  author={Manogaran, Harish Babu and Maruf, M and Daw, Arka and Mehrab, Kazi Sajeed and Charpentier, Caleb Patrick and Uyeda, Josef C and Dahdul, Wasila and Thompson, Matthew J and Campolongo, Elizabeth G and Provost, Kaiya L and others},
  abstract={A grand challenge in biology is to discover evolutionary traits - features of organisms common to a group of species with a shared ancestor in the tree of life (also referred to as phylogenetic tree). With the growing availability of image repositories in biology, there is a tremendous opportunity to discover evolutionary traits directly from images in the form of a hierarchy of prototypes. However, current prototype-based methods are mostly designed to operate over a flat structure of classes and face several challenges in discovering hierarchical prototypes, including the issue of learning over-specific features at internal nodes. To overcome these challenges, we introduce the framework of Hierarchy aligned Commonality through Prototypical Networks (HComP-Net). We empirically show that HComP-Net learns prototypes that are accurate, semantically consistent, and generalizable to unseen species in comparison to baselines on birds, butterflies, and fishes datasets.},
  journal={arXiv preprint arXiv:2409.02335},
  year={2024},
  publisher={Arxiv},
  html={https://arxiv.org/abs/2409.02335}
}

@article{maruf2024vlm4bio,
  abbr={NeurIPS 2024},
  bibtex_show={true},
  title={VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images},
  author={Maruf, M and Daw, Arka and Mehrab, Kazi Sajeed and Manogaran, Harish Babu and Neog, Abhilash and Sawhney, Medha and Khurana, Mridul and Balhoff, James P and Bakis, Yasin and Altintas, Bahadir and others},
  abstract={Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models (VLMs). We ask if pre-trained VLMs can aid scientists in answering a range of biologically relevant questions without any additional fine-tuning. In this paper, we evaluate the effectiveness of 12 state-of-the-art (SOTA) VLMs in the field of organismal biology using a novel dataset, VLM4Bio, consisting of 469K question-answer pairs involving 30K images from three groups of organisms: fishes, birds, and butterflies, covering five biologically relevant tasks. We also explore the effects of applying prompting techniques and tests for reasoning hallucination on the performance of VLMs, shedding new light on the capabilities of current SOTA VLMs in answering biologically relevant questions using images. The code and datasets for running all the analyses reported in this paper can be found at this https URL.},
  journal={in proceedings of Neural Information Processing Systems (NeurIPS) 2024},
  year={2024},
  publisher={NeurIPS},
  html={https://neurips.cc/virtual/2024/poster/97668}
}

@article{mehrab2024fish,
  abbr={Arxiv},
  bibtex_show={true},
  title={Fish-Vista: A Multi-Purpose Dataset for Understanding \& Identification of Traits from Images},
  author={Mehrab, Kazi Sajeed and Maruf, M and Daw, Arka and Manogaran, Harish Babu and Neog, Abhilash and Khurana, Mridul and Altintas, Bahadir and Bakis, Yasin and Campolongo, Elizabeth G and Thompson, Matthew J and others},
  abstract={Fishes are integral to both ecological systems and economic sectors, and studying fish traits is crucial for understanding biodiversity patterns and macro-evolution trends. To enable the analysis of visual traits from fish images, we introduce the Fish-Visual Trait Analysis (Fish-Vista) dataset - a large, annotated collection of about 60K fish images spanning 1900 different species, supporting several challenging and biologically relevant tasks including species classification, trait identification, and trait segmentation. These images have been curated through a sophisticated data processing pipeline applied to a cumulative set of images obtained from various museum collections. Fish-Vista provides fine-grained labels of various visual traits present in each image. It also offers pixel-level annotations of 9 different traits for 2427 fish images, facilitating additional trait segmentation and localization tasks. The ultimate goal of Fish-Vista is to provide a clean, carefully curated, high-resolution dataset that can serve as a foundation for accelerating biological discoveries using advances in AI. Finally, we provide a comprehensive analysis of state-of-the-art deep learning techniques on Fish-Vista.},
  journal={arXiv preprint arXiv:2407.08027},
  year={2024},
  publisher={Arxiv},
  html={https://arxiv.org/abs/2407.08027}
}

@article{khurana2024hierarchical,
  abbr={ECCV 2024},
  bibtex_show={true},
  title={Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution},
  author={Khurana, Mridul and Daw, Arka and Maruf, M and Uyeda, Josef C and Dahdul, Wasila and Charpentier, Caleb and Bak{\i}{\c{s}}, Yasin and Bart Jr, Henry L and Mabee, Paula M and Lapp, Hilmar and others},
  abstract={A central problem in biology is to understand how organisms evolve and adapt to their environment by acquiring variations in the observable characteristics or traits of species across the tree of life. With the growing availability of large-scale image repositories in biology and recent advances in generative modeling, there is an opportunity to accelerate the discovery of evolutionary traits automatically from images. Toward this goal, we introduce Phylo-Diffusion, a novel framework for conditioning diffusion models with phylogenetic knowledge represented in the form of HIERarchical Embeddings (HIER-Embeds). We also propose two new experiments for perturbing the embedding space of Phylo-Diffusion: trait masking and trait swapping, inspired by counterpart experiments of gene knockout and gene editing/swapping. Our work represents a novel methodological advance in generative modeling to structure the embedding space of diffusion models using tree-based knowledge. Our work also opens a new chapter of research in evolutionary biology by using generative models to visualize evolutionary changes directly from images. We empirically demonstrate the usefulness of Phylo-Diffusion in capturing meaningful trait variations for fishes and birds, revealing novel insights about the biological mechanisms of their evolution.},
  journal={in proceedings of European Conference on Computer Vision (ECCV) 2024},
  year={2024},
  publisher={ECCV},
  html={https://eccv.ecva.net/virtual/2024/poster/2061}
}

@article{kashi2024learning,
  abbr={ICML 2024},
  bibtex_show={true},
  title={Learning the boundary-to-domain mapping using Lifting Product Fourier Neural Operators for partial differential equations},
  author={Kashi, Aditya and Daw, Arka and Meena, Muralikrishnan Gopalakrishnan and Lu, Hao},
  abstract={Neural operators such as the Fourier Neural Operator (FNO) have been shown to provide resolution-independent deep learning models that can learn mappings between function spaces. For example, an initial condition can be mapped to the solution of a partial differential equation (PDE) at a future time-step using a neural operator. Despite the popularity of neural operators, their use to predict solution functions over a domain given only data over the boundary (such as a spatially varying Dirichlet boundary condition) remains unexplored. In this paper, we refer to such problems as boundary-to-domain problems; they have a wide range of applications in areas such as fluid mechanics, solid mechanics, heat transfer etc. We present a novel FNO-based architecture, named Lifting Product FNO (or LP-FNO) which can map arbitrary boundary functions defined on the lower-dimensional boundary to a solution in the entire domain. Specifically, two FNOs defined on the lower-dimensional boundary are lifted into the higher dimensional domain using our proposed lifting product layer. We demonstrate the efficacy and resolution independence of the proposed LP-FNO for the 2D Poisson equation.},
  journal={AI4Science Workshop at International Conference on Machine Learning (ICML) 2024},
  year={2024},
  publisher={ICML},
  html={https://arxiv.org/abs/2406.16740}
}

@article{sawhney2024motion,
  abbr={AIS},
  bibtex_show={true},
  title={Motion Enhanced Multi-Level Tracker (MEMTrack): A Deep Learning-Based Approach to Microrobot Tracking in Dense and Low-Contrast Environments},
  author={Sawhney, Medha and Karmarkar, Bhas and Leaman, Eric J and Daw, Arka and Karpatne, Anuj and Behkam, Bahareh},
  abstract={Tracking microrobots is challenging due to their minute size and high speed. In biomedical applications, this challenge is exacerbated by the dense surrounding environments with feature sizes and shapes comparable to microrobots. Herein, Motion Enhanced Multi-level Tracker (MEMTrack) is introduced for detecting and tracking microrobots in dense and low-contrast environments. Informed by the physics of microrobot motion, synthetic motion features for deep learning-based object detection and a modified Simple Online and Real-time Tracking (SORT)algorithm with interpolation are used for tracking. MEMTrack is trained and tested using bacterial micromotors in collagen (tissue phantom), achieving precision and recall of 76% and 51%, respectively. Compared to the state-of-the-art baseline models, MEMTrack provides a minimum of 2.6-fold higher precision with a reasonably high recall. MEMTrack's generalizability to unseen (aqueous) media and its versatility in tracking microrobots of different shapes, sizes, and motion characteristics are shown. Finally, it is shown that MEMTrack localizes objects with a root-mean-square error of less than 1.84 μm and quantifies the average speed of all tested systems with no statistically significant difference from the laboriously produced manual tracking data. MEMTrack significantly advances microrobot localization and tracking in dense and low-contrast settings and can impact fundamental and translational microrobotic research.},
  journal={Advanced Intelligent Systems},
  volume={6},
  number={4},
  pages={2300590},
  year={2024},
  publisher={Wiley Online Library},
  html={https://onlinelibrary.wiley.com/doi/full/10.1002/aisy.202300590},
}

@article{daw2024physics,
  abbr={Ph.D. Dissertation},
  bibtex_show={true},
  title={Physics-informed Machine Learning with Uncertainty Quantification},
  author={Daw, Arka},
  abstract={Physics Informed Machine Learning (PIML) has emerged as the forefront of research in scientific machine learning with the key motivation of systematically coupling machine learning (ML) methods with prior domain knowledge often available in the form of physics supervision. Uncertainty quantification (UQ) is an important goal in many scientific use-cases, where the obtaining reliable ML model predictions and accessing the potential risks associated with them is crucial. In this thesis, we propose novel methodologies in three key areas for improving uncertainty quantification for PIML. First, we propose to explicitly infuse the physics prior in the form of monotonicity constraints through architectural modifications in neural networks for quantifying uncertainty. Second, we demonstrate a more general framework for quantifying uncertainty with PIML that is compatible with generic forms of physics supervision such as PDEs and closed form equations. Lastly, we study the limitations of physics-based loss in the context of Physics-informed Neural Networks (PINNs), and develop an efficient sampling strategy to mitigate the failure modes.},
  year={2024},
  publisher={Virginia Tech},
  html={https://vtechworks.lib.vt.edu/items/04ca13c4-5ae7-4381-8a97-cc3f126724c2},
}

@article{ladwig2024modular,
  abbr={JAMES},
  bibtex_show={true},
  title={Modular Compositional Learning Improves 1D Hydrodynamic Lake Model Performance by Merging Process-Based Modeling With Deep Learning},
  author={Ladwig, Robert and Daw, Arka and Albright, Ellen A and Buelo, Cal and Karpatne, Anuj and Meyer, Michael Frederick and Neog, Abhilash and Hanson, Paul C and Dugan, Hilary A},
  abstract={Hybrid Knowledge-Guided Machine Learning (KGML) models, which are deep learning models that utilize scientific theory and process-based model simulations, have shown improved performance over their process-based counterparts for the simulation of water temperature and hydrodynamics. We highlight the modular compositional learning (MCL) methodology as a novel design choice for the development of hybrid KGML models in which the model is decomposed into modular sub-components that can be process-based models and/or deep learning models. We develop a hybrid MCL model that integrates a deep learning model into a modularized, process-based model. To achieve this, we first train individual deep learning models with the output of the process-based models. In a second step, we fine-tune one deep learning model with observed field data. In this study, we replaced process-based calculations of vertical diffusive transport with deep learning. Finally, this fine-tuned deep learning model is integrated into the process-based model, creating the hybrid MCL model with improved overall projections for water temperature dynamics compared to the original process-based model. We further compare the performance of the hybrid MCL model with the process-based model and two alternative deep learning models and highlight how the hybrid MCL model has the best performance for projecting water temperature, Schmidt stability, buoyancy frequency, and depths of different isotherms. Modular compositional learning can be applied to existing modularized, process-based model structures to make the projections more robust and improve model performance by letting deep learning estimate uncertain process calculations.},
  journal={Journal of Advances in Modeling Earth Systems},
  volume={16},
  number={1},
  pages={e2023MS003953},
  year={2024},
  publisher={Wiley Online Library},
  html={https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2023MS003953}
}

@article{maruf2023beyond,
  abbr={Arxiv},
  bibtex_show={true},
  title={Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation},
  author={Maruf, M and Daw, Arka and Dutta, Amartya and Bu, Jie and Karpatne, Anuj},
  abstract={In recent years, several Weakly Supervised Semantic Segmentation (WS3) methods have been proposed that use class activation maps (CAMs) generated by a classifier to produce pseudo-ground truths for training segmentation models. While CAMs are good at highlighting discriminative regions (DR) of an image, they are known to disregard regions of the object that do not contribute to the classifier's prediction, termed non-discriminative regions (NDR). In contrast, attribution methods such as saliency maps provide an alternative approach for assigning a score to every pixel based on its contribution to the classification prediction. This paper provides a comprehensive comparison between saliencies and CAMs for WS3. Our study includes multiple perspectives on understanding their similarities and dissimilarities. Moreover, we provide new evaluation metrics that perform a comprehensive assessment of WS3 performance of alternative methods w.r.t. CAMs. We demonstrate the effectiveness of saliencies in addressing the limitation of CAMs through our empirical studies on benchmark datasets. Furthermore, we propose random cropping as a stochastic aggregation technique that improves the performance of saliency, making it a strong alternative to CAM for WS3.},
  journal={arXiv preprint arXiv:2308.11052},
  year={2023},
  publisher={Arxiv},
  html={https://arxiv.org/abs/2308.11052}
}

@inproceedings{sawhney2023detecting,
  abbr={CVPR 2023},
  bibtex_show={true},
  title={Detecting and Tracking Hard-to-Detect Bacteria in Dense Porous Backgrounds},
  author={Sawhney, Medha and Karmarkar, Bhas and Leaman, Eric J and Daw, Arka and Karpatne, Anuj and Behkam, Bahareh},
  abstract={Studying bacteria motility is crucial to understanding and controlling biomedical and ecological phenomena involving bacteria. Tracking bacteria in complex environments such as polysaccharides (agar) or protein (collagen) hydrogels is a challenging task due to the lack of visually distinguishable features between bacteria and surrounding environment, making state-of-the-art methods for tracking easily recognizable objects such as pedestrians and cars unsuitable for this application. We propose a novel pipeline for detecting and tracking bacteria in bright-field microscopy videos involving bacteria in complex backgrounds. Our pipeline uses motion-based features and combines multiple models for detecting bacteria of varying difficulty levels. We apply multiple filters to prune false positive detections, and then use the SORT tracking algorithm with interpolation in case of missing detections. Our results demonstrate that our pipeline can accurately track hard-to-detect bacteria, achieving a high precision and recall. },
  year={2023},
  organization={CVPR Workshop on CV4Animals 2023},
  publisher={CVPR},
  html={https://par.nsf.gov/biblio/10470115}
}

@inproceedings{daw2022mitigating,
  abbr={ICML 2023},
  bibtex_show={true},
  author = {Daw, Arka and Bu, Jie and Wang, Sifan and Perdikaris, Paris and Karpatne, Anuj},
  title = {Mitigating propagation failures in physics-informed neural networks using retain-resample-release (r3) sampling},
  year = {2023},
  publisher = {JMLR.org},
  abstract = {Despite the success of physics-informed neural networks (PINNs) in approximating partial differential equations (PDEs), PINNs can sometimes fail to converge to the correct solution in problems involving complicated PDEs. This is reflected in several recent studies on characterizing the "failure modes" of PINNs, although a thorough understanding of the connection between PINN failure modes and sampling strategies is missing. In this paper, we provide a novel perspective of failure modes of PINNs by hypothesizing that training PINNs relies on successful "propagation" of solution from initial and/or boundary condition points to interior points. We show that PINNs with poor sampling strategies can get stuck at trivial solutions if there are propagation failures, characterized by highly imbalanced PDE residual fields. To mitigate propagation failures, we propose a novel Retain-Resample-Release sampling (R3) algorithm that can incrementally accumulate collocation points in regions of high PDE residuals with little to no computational overhead. We provide an extension of R3 sampling to respect the principle of causality while solving timedependent PDEs. We theoretically analyze the behavior of R3 sampling and empirically demonstrate its efficacy and efficiency in comparison with baselines on a variety of PDE problems.},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  articleno = {288},
  numpages = {39},
  location = {Honolulu, Hawaii, USA},
  series = {ICML'23},
  html={https://dl.acm.org/doi/10.5555/3618408.3618696}
}

@inproceedings{daw2022source,
  abbr={NeurIPS 2022},
  bibtex_show={true},
  title={Source Identification and Field Reconstruction of Advection-Diffusion Process from Sparse Sensor Measurements},
  author={Daw, Arka and Karpatne, Anuj and Yeo, Kyongmin and Klein, Levente},
  year={2022},
  organization={Conference on Neural Information Processing Systems},
  abstract = {Inferring the source information of greenhouse gases, such as methane, from spatially sparse sensor observations is an essential element in mitigating climate change. While it is well understood that the complex behavior of the atmospheric dispersion of such pollutants is governed by the Advection-Diffusion equation, it is difficult to directly apply the governing equations to identify the source information because of the spatially sparse observations, i.e., the pollution concentration is known only at the sensor locations. Here, we develop a multi-task learning framework that can provide high-fidelity reconstruction of the concentration field and identify emission characteristics of the pollution sources such as their location, emission strength, etc. from sparse sensor observations. We demonstrate that our proposed framework is able to achieve accurate reconstruction of the methane concentrations from sparse sensor measurements as well as precisely pin-point the location and emission strength of these pollution sources.},
  html={https://vtechworks.lib.vt.edu/items/3cc431b1-9519-4407-ba4f-06f58f746303},
  publisher={NeurIPS}
}



@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
